{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sprutxz/English-To-Python/blob/main/EnglishToPython.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "xSdUCIuxC2kc"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#import seaborn as sns\n",
        "from timeit import default_timer as timer\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator, vocab\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from tokenize import tokenize, untokenize\n",
        "import io\n",
        "import re\n",
        "#from nltk.stem import PorterStemmer\n",
        "\n",
        "# Setting the device for model\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ebw75vi2DZp_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['# write a python program to add two numbers \\n', 'num1 = 1.5\\n', 'num2 = 6.3\\n', 'sum = num1 + num2\\n', \"print(f'Sum: {sum}')\\n\", '\\n', '\\n', '# write a python function to add two user provided numbers and return the sum\\n', 'def add_two_numbers(num1, num2):\\n', '    sum = num1 + num2\\n', '    return sum\\n']\n"
          ]
        }
      ],
      "source": [
        "# Examining the dataset\n",
        "with open('english_python_data.txt',\"r\") as data_file:\n",
        "  print(data_file.readlines()[:11]) # Printing out the last 5 lines of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "#custom tokenizer for python code\n",
        "def tokenize_python_code(python_code_str):\n",
        "    python_tokens = list(tokenize(io.BytesIO(python_code_str.encode('utf-8')).readline))\n",
        "    tokenized_output = []\n",
        "    for i in range(0, len(python_tokens)):\n",
        "        tokenized_output.append(python_tokens[i].string)\n",
        "    return tokenized_output\n",
        "\n",
        "tokenizer = get_tokenizer('spacy',language='en_core_web_sm') #tokenizer function for the english text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "39OhkMrlDaSH"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>solution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python program to add two numbers</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provid...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n\\tsum = num1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a program to find and print the largest ...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the smallest...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>write a python function to merge two given lis...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n\\treturn l1 + l2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4991</th>\n",
              "      <td>write a program to print bit wise and of two n...</td>\n",
              "      <td>a = 60            # 60 = 0011 1100\\nb = 13    ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4992</th>\n",
              "      <td>write a program to print bit wise or of two nu...</td>\n",
              "      <td>a = 60\\nb = 13\\nc = a | b\\nprint(\"OR\", c)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4993</th>\n",
              "      <td>write a program to print bit wise xor of two n...</td>\n",
              "      <td>a = 60\\nb = 13\\nc = a ^ b\\nprint(\"XOR\", c)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>write a program to calculate binary ones compl...</td>\n",
              "      <td>a = 60\\nc = ~a\\nprint(\"Binary Ones Complement\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>write a program to binary left shift a number</td>\n",
              "      <td>c = a &lt;&lt; 2\\nprint(\"Binary Left Shift\", c)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4996 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               question  \\\n",
              "0             write a python program to add two numbers   \n",
              "1     write a python function to add two user provid...   \n",
              "2     write a program to find and print the largest ...   \n",
              "3     write a program to find and print the smallest...   \n",
              "4     write a python function to merge two given lis...   \n",
              "...                                                 ...   \n",
              "4991  write a program to print bit wise and of two n...   \n",
              "4992  write a program to print bit wise or of two nu...   \n",
              "4993  write a program to print bit wise xor of two n...   \n",
              "4994  write a program to calculate binary ones compl...   \n",
              "4995      write a program to binary left shift a number   \n",
              "\n",
              "                                               solution  \n",
              "0     num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...  \n",
              "1     def add_two_numbers(num1, num2):\\n\\tsum = num1...  \n",
              "2     num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >= n...  \n",
              "3     num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...  \n",
              "4            def merge_lists(l1, l2):\\n\\treturn l1 + l2  \n",
              "...                                                 ...  \n",
              "4991  a = 60            # 60 = 0011 1100\\nb = 13    ...  \n",
              "4992          a = 60\\nb = 13\\nc = a | b\\nprint(\"OR\", c)  \n",
              "4993         a = 60\\nb = 13\\nc = a ^ b\\nprint(\"XOR\", c)  \n",
              "4994  a = 60\\nc = ~a\\nprint(\"Binary Ones Complement\"...  \n",
              "4995          c = a << 2\\nprint(\"Binary Left Shift\", c)  \n",
              "\n",
              "[4996 rows x 2 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating a Regular Expression (Regex) pattern of urls to remove them\n",
        "url_pattern = re.compile(r\"https?://\\S+\")\n",
        "\n",
        "src_doc = []\n",
        "tgt_doc = []\n",
        "\n",
        "i = 0\n",
        "# Making a dataset\n",
        "with open('english_python_data.txt',\"r\") as data_file:\n",
        "  data_lines = data_file.readlines()\n",
        "  dps = [] # List of dictionaries\n",
        "  dp = None # The current problem and solution\n",
        "  for line in data_lines:\n",
        "    if line[0] == \"#\":\n",
        "      tab_count = 0\n",
        "      loop_indent = 0\n",
        "      dict = {0: 0}\n",
        "      if dp:\n",
        "        dp['solution'] = ''.join(dp['solution'])\n",
        "        dp['solution'] = re.sub(r'\\n+', '\\n', dp['solution']) #replaces multiple newlines with a single newline\n",
        "        dp['solution'] = re.sub(r'(\\n\\t*)*$', '', dp['solution']) #removes any newlines at the end of the solution\n",
        "        dp['solution'] = re.sub(r'^\\n', '', dp['solution']) #removes any newlines at the beginning of the solution\n",
        "          \n",
        "        tgt_doc.append(tokenize_python_code(dp['solution']))  \n",
        "        dps.append(dp)\n",
        "      dp = {\"question\": None, \"solution\": []}\n",
        "      dp['question'] = line[1:].strip(\"\\n \") # Removing any \\n in the question\n",
        "      dp['question'] = re.sub(r'^\\d+ ', \"\", dp['question']) # If the question starts with numbers, I remove them.\n",
        "      dp['question'] = url_pattern.sub('',dp['question']) # Replacing any urls\n",
        "      dp['question'] = dp['question'].lower() # lowercasing the question\n",
        "      dp['question'] = re.sub(r\"([.!?])\",\"\",dp['question']) # removing any punctuation\n",
        "      src_doc.append(tokenizer(dp['question'])) # Splitting the question into words\n",
        "    else:\n",
        "      line = re.sub(r'( |\\t)*\\n( |\\t)*', '\\n', line) #replaces spaces before a newline with a  just a newline\n",
        "      if line == '\\n':\n",
        "        continue\n",
        "      \n",
        "      space_count = len(line) - len(line.lstrip(' '))\n",
        "      if loop_indent > space_count:\n",
        "        tab_count = dict[space_count]\n",
        "        loop_indent = space_count\n",
        "      if(len(dp['solution'])!=0):\n",
        "        if (bool(re.search(r':\\n$', dp['solution'][-1]))):\n",
        "          dict[space_count] = tab_count\n",
        "          loop_indent = space_count\n",
        "\n",
        "      \n",
        "      if tab_count > 0 and bool(re.search(r',\\n', dp['solution'][-1])!=True) and bool(re.search(fr'^(\\t){{{tab_count}}}', line))!=True:\n",
        "        line = re.sub(r'^ *', '\\t'*tab_count, line)#replaces the first space with a tab\n",
        "      \n",
        "      if re.search(r'^(if|else|elif|for|while|def|class|try|except|finally|with)', line):\n",
        "        tab_count += 1 \n",
        "      \n",
        "      \n",
        "      dp['solution'].append(line)\n",
        "      \n",
        "\n",
        "# converting the data to a table for easier viewing\n",
        "dataset = pd.DataFrame(dps)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "8qTVVnZaDb6O"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "write a program to print the multiplication table of a given number\n",
            "num = 9\n",
            "for i in range(1, 11):\n",
            "\tprint(f\"{num} x {i} = {num*i}\")\n"
          ]
        }
      ],
      "source": [
        "# Looking at the first question and the corresponding solution\n",
        "print(dataset.loc[9,'question'])\n",
        "print(dataset.loc[9,'solution'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "src_emb = gensim.models.Word2Vec.load(\"src_emb.model\") # Loading the source language model\n",
        "tgt_emb = gensim.models.Word2Vec.load(\"tgt_emb.model\") # Loading the target language model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating dictionaries for the tokenizers and the vocabularies\n",
        "SRC_LANGUAGE = 'en'\n",
        "TGT_LANGUAGE = 'python'\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3 # Tokens for Unknown, Padding, start of sentence, end of sentence\n",
        "vocabularies = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocabularies[SRC_LANGUAGE] = vocab(src_emb.wv.key_to_index, min_freq=0) # Creating a vocabulary for the source language\n",
        "vocabularies[TGT_LANGUAGE] = vocab(tgt_emb.wv.key_to_index, min_freq=0) # Creating a vocabulary for the target language\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "  vocabularies[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "l-4VEO2Oe25o"
      },
      "outputs": [],
      "source": [
        "# Positional Encoding module -> this class is the positional encoder (see above for details)\n",
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self,emb_size:int, dropout:float, maxlen:int = 5000):\n",
        "    super().__init__()\n",
        "    den = torch.exp(-torch.arange(0,emb_size,2)*math.log(10000) / emb_size)\n",
        "    pos = torch.arange(0,maxlen).reshape(maxlen,1)\n",
        "    pos_embedding = torch.zeros((maxlen,emb_size))\n",
        "    pos_embedding[:,0::2] = torch.sin(pos * den)\n",
        "    pos_embedding[:,1::2] = torch.cos(pos * den)\n",
        "    pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # Saving the positional encoding in the model state dict, but making sure PyTorch doesn't \"train\"\n",
        "    # these parameters because they don't need to be trained\n",
        "    self.register_buffer('pos_embedding',pos_embedding)\n",
        "\n",
        "  def forward(self,token_embedding: Tensor):\n",
        "    return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# # Converting the tokens into embeddings\n",
        "# class TokenEmbedding(nn.Module):\n",
        "#   def __init__(self,vocab_size: int, emb_size):\n",
        "#     super().__init__()\n",
        "#     self.embedding = nn.Embedding(vocab_size,emb_size)\n",
        "#     self.embed_size = emb_size\n",
        "\n",
        "#   def forward(self,tokens:Tensor):\n",
        "#     return self.embedding(tokens.long()) * math.sqrt(self.embed_size) # we multiply by square root of embedding size to scale. The Transformer paper mentions this.\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "  def __init__(self, vocab_size: int, emb_size: int, word2vec_model_path: str):\n",
        "    super().__init__()\n",
        "    self.word2vec_model = gensim.models.Word2Vec.load(word2vec_model_path)\n",
        "    self.embedding = nn.Embedding(vocab_size+4, emb_size)\n",
        "    self.embed_size = emb_size\n",
        "\n",
        "    # Initialize the embedding weights with the Word2Vec vectors\n",
        "    self.embedding.weight.data[4:].copy_(torch.from_numpy(self.word2vec_model.wv.vectors))\n",
        "\n",
        "  def forward(self, tokens: Tensor):\n",
        "    return self.embedding(tokens.long()) * math.sqrt(self.embed_size)\n",
        "  \n",
        "    \n",
        "\n",
        "# The Actual Model\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "  def __init__(self, num_encoder_layers:int, num_decoder_layers:int, emb_size:int, nhead:int, src_vocab_size:int, tgt_vocab_size:int, dim_feedforward: int=512, dropout:float = 0.1):\n",
        "    super().__init__()\n",
        "    self.transformer = Transformer(d_model=emb_size, nhead=nhead, num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers,dim_feedforward=dim_feedforward,dropout=dropout,\n",
        "                                      batch_first=True)\n",
        "    self.generator = nn.Linear(emb_size,tgt_vocab_size) # A layer to convert the matrix (seq_len, emb_size) to (seq_len, tgt_vocab_size)\n",
        "    self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size, \"src_emb.model\")\n",
        "    self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size,emb_size, \"tgt_emb.model\")\n",
        "\n",
        "    # Getting the positional encodings\n",
        "    self.positional_encoding = PositionalEncoding(emb_size,dropout=dropout)\n",
        "\n",
        "  def forward(self, src:Tensor, trg: Tensor, src_mask: Tensor, tgt_mask: Tensor, src_padding_mask: Tensor, tgt_padding_mask: Tensor,\n",
        "              memory_key_padding_mask: Tensor):\n",
        "\n",
        "    # Embedding both the input and output\n",
        "    src_embedding = self.positional_encoding(self.src_tok_emb(src))\n",
        "    tgt_embedding = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "\n",
        "    # Getting the output\n",
        "    output = self.transformer(src_embedding, tgt_embedding, src_mask, tgt_mask, None, src_padding_mask,tgt_padding_mask,memory_key_padding_mask)\n",
        "\n",
        "    # Getting the logits\n",
        "    return self.generator(output)\n",
        "  \n",
        "\n",
        "  # Encoding the input\n",
        "  def encode(self, src: Tensor, src_mask: Tensor):\n",
        "    embedding = self.positional_encoding(self.src_tok_emb(src))\n",
        "    encoder_output = self.transformer.encoder(embedding, src_mask)\n",
        "    return encoder_output\n",
        "\n",
        "  # Decoding the output\n",
        "  def decode(self,tgt:Tensor, memory: Tensor, tgt_mask:Tensor):\n",
        "    tgt_embedding = self.tgt_tok_emb(tgt)\n",
        "    return self.transformer.decoder(self.positional_encoding(tgt_embedding), memory, tgt_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "-Teu_4Usi7Vl"
      },
      "outputs": [],
      "source": [
        "# Defining the lookahead mask that will prevent the model from looking ahead during training\n",
        "# Also need to define masks that will mask the padding tokens.\n",
        "# If we don't mask the padding tokens, the model will end up taking the values of the padding into account\n",
        "# into prediction\n",
        "\n",
        "# Generating the lookahead mask\n",
        "def generate_square_subsequent_mask(sz):\n",
        "  mask = (torch.triu(torch.ones((sz,sz),device=DEVICE)) == 1).transpose(0,1)\n",
        "  mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "  return mask\n",
        "\n",
        "# Creating the other mask\n",
        "def create_mask(src, tgt):\n",
        "  src_seq_len = src.shape[1]\n",
        "  tgt_seq_len = tgt.shape[1]\n",
        "\n",
        "  tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "  src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "  src_padding_mask = (src == PAD_IDX)\n",
        "  tgt_padding_mask = (tgt == PAD_IDX)\n",
        "  return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "qjIQzZENjLgw"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into training and testing\n",
        "#training, testing = train_test_split(dataset,test_size=0.2,random_state=42,shuffle=True)\n",
        "\n",
        "train_size = int(len(dataset)*0.8)\n",
        "test_size = len(dataset) - train_size\n",
        "training, testing = random_split(dataset,[train_size,test_size])\n",
        "\n",
        "# Running the data through a pipeline to get the transformed and prepared dataset\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "  def func(txt_input):\n",
        "    for transform in transforms:\n",
        "      txt_input = transform(txt_input)\n",
        "    return txt_input\n",
        "  return func\n",
        "\n",
        "# Function to add BOS/EOS and create tensor for input sequence indicies\n",
        "def tensor_transform(token_ids):\n",
        "  return torch.cat((torch.tensor([SOS_IDX]),torch.tensor(token_ids),torch.tensor([EOS_IDX])))\n",
        "\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "  text_transform[ln] = sequential_transforms(tokenizer,vocabularies[ln],tensor_transform) # Tokenize, Convert to Indicies, then Add Special Tokens\n",
        "\n",
        "# function to put all the data samples into batches\n",
        "def collate_fn(batch):\n",
        "  src_batch, tgt_batch = [], []\n",
        "\n",
        "  # Iterating through the questions\n",
        "  for X in batch.dataset['question'].values:\n",
        "    token_tensor = text_transform[SRC_LANGUAGE](X.strip('\\n\\t'))\n",
        "    #token_tensor = token_tensor[:-1]\n",
        "    src_batch.append(token_tensor)\n",
        "\n",
        "  # Iterating through the solutions\n",
        "  for y in batch.dataset['solution'].values:\n",
        "    token_tensor = text_transform[TGT_LANGUAGE](y.strip('\\n\\t'))\n",
        "    #token_tensor = token_tensor[:-1]\n",
        "    tgt_batch.append(token_tensor)\n",
        "\n",
        "  src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "  tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "  return src_batch.T, tgt_batch.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "wZUdqI_WkrPp"
      },
      "outputs": [],
      "source": [
        "# Defining the model, loss function, and optimizer\n",
        "torch.manual_seed(10)\n",
        "\n",
        "SRC_VOCAB_SIZE = len(vocabularies[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocabularies[TGT_LANGUAGE])\n",
        "EMB_SIZE = 64\n",
        "NHEAD = 4\n",
        "FFN_HID_DIM = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "\n",
        "# Defining the model\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "# Setting the parameters using the xavier uniform distribution\n",
        "for p in transformer.parameters():\n",
        "  if p.dim() > 1:\n",
        "    nn.init.xavier_uniform_(p)\n",
        "\n",
        "# Putting the model on GPU\n",
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "# Defining the loss function\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_IDX) # makes sure that the padding token doesn't contribute to the loss function!\n",
        "\n",
        "# Defining the optimizer\n",
        "optimizer = optim.AdamW(transformer.parameters(),lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "21DZ5Z-Vkb0h"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model,optimizer):\n",
        "  # Setting the model to training mode\n",
        "  model.train()\n",
        "  losses = 0\n",
        "\n",
        "  # Preparing the data\n",
        "  X,y = collate_fn(training)\n",
        "  training_dataset = TensorDataset(X,y)\n",
        "  train_dataloader = DataLoader(training_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "  # Iterating through the data\n",
        "  for src, tgt in train_dataloader:\n",
        "    src = src.to(DEVICE)\n",
        "    tgt = tgt.to(DEVICE)\n",
        "    print(tgt.shape)\n",
        "    tgt_in = tgt[:,:-1]\n",
        "\n",
        "    # Getting the masks\n",
        "    src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt)\n",
        "    logits = model(src,tgt_in, src_mask, tgt_mask, src_padding_mask,tgt_padding_mask,src_padding_mask) # memory is the encoder outputs\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    #print(tgt)\n",
        "    tgt_out = tgt[:,1:]\n",
        "    #print(tgt_out)\n",
        "    #print(logits)\n",
        "    #print(tgt_out.shape)\n",
        "    #logits = logits.contiguous().view(-1, logits.shape[-1])\n",
        "    #tgt_out = tgt_out.contiguous().view(-1)\n",
        "    #loss = loss_fn(logits.reshape(logits.size(0),-1,6969),tgt_out)\n",
        "    #print(logits.shape)\n",
        "    #print(tgt_out.shape)\n",
        "    loss = loss_fn(logits,tgt_out)\n",
        "    loss.backward() # Back propagation, calculating the gradients\n",
        "\n",
        "    optimizer.step()\n",
        "    losses += loss.item()\n",
        "\n",
        "  return losses / len(list(train_dataloader)) # Getting the average loss per example\n",
        "\n",
        "# Evaluation Loop\n",
        "def evaluate(model):\n",
        "  model.eval()\n",
        "  losses = 0\n",
        "\n",
        "  # Preparing the data\n",
        "  X,y = collate_fn(testing)\n",
        "  testing_data = TensorDataset(X,y)\n",
        "  val_dataloader = DataLoader(testing_data, batch_size=BATCH_SIZE)\n",
        "\n",
        "  # Iterating through the data\n",
        "  for src, tgt in val_dataloader:\n",
        "    src = src.to(DEVICE)\n",
        "    tgt = tgt.to(DEVICE)\n",
        "\n",
        "    tgt_input = tgt[:,:-1] # Getting the sentence except the EOS since EOS is never inputted to decoder\n",
        "\n",
        "    # Getting the masks\n",
        "    src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "    logits = model(src,tgt_input, src_mask, tgt_mask, src_padding_mask,tgt_padding_mask,src_padding_mask) # memory is the encoder outputs\n",
        "    tgt_out = tgt[:,1:]\n",
        "    loss = loss_fn(logits.reshape(-1,logits.shape[-1]),tgt_out.reshape(-1))\n",
        "    losses += loss.item()\n",
        "\n",
        "  return losses / len(list(val_dataloader)) # Getting the average loss per example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 557])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/leroy/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  2,  81,   6,  ...,   1,   1,   1],\n",
            "        [  2,  15,   0,  ...,   1,   1,   1],\n",
            "        [  2,  81,   6,  ...,   1,   1,   1],\n",
            "        ...,\n",
            "        [  2, 159,   6,  ...,   1,   1,   1],\n",
            "        [  2,  15,   0,  ...,   1,   1,   1],\n",
            "        [  2,  23,   6,  ...,   1,   1,   1]], device='cuda:0')\n",
            "tensor([[ 81,   6, 725,  ...,   1,   1,   1],\n",
            "        [ 15,   0,   4,  ...,   1,   1,   1],\n",
            "        [ 81,   6,  46,  ...,   1,   1,   1],\n",
            "        ...,\n",
            "        [159,   6,   7,  ...,   1,   1,   1],\n",
            "        [ 15,   0,   0,  ...,   1,   1,   1],\n",
            "        [ 23,   6, 240,  ...,   1,   1,   1]], device='cuda:0')\n",
            "tensor([[[ 5.7320e-02,  2.5325e-04, -1.8323e-01,  ...,  5.8100e-02,\n",
            "           3.2641e-02, -2.3413e-01],\n",
            "         [-4.1778e-02,  3.0606e-04, -1.8116e-01,  ...,  6.2038e-02,\n",
            "           4.4804e-02, -1.7738e-01],\n",
            "         [-6.8417e-03,  4.6465e-02, -1.5027e-01,  ...,  1.2183e-01,\n",
            "           8.8714e-03, -1.7501e-01],\n",
            "         ...,\n",
            "         [-8.7399e-04,  6.4898e-02, -1.8188e-01,  ...,  3.4733e-04,\n",
            "          -1.8782e-02, -1.7895e-01],\n",
            "         [-1.2708e-02, -1.3348e-02, -2.3805e-01,  ..., -5.2943e-02,\n",
            "           2.2195e-02, -1.3812e-01],\n",
            "         [ 4.6795e-02, -6.4796e-02, -1.4758e-01,  ...,  4.5209e-02,\n",
            "           1.0327e-01, -1.7958e-01]],\n",
            "\n",
            "        [[ 1.6107e-03, -2.8149e-02, -1.9263e-01,  ..., -7.6022e-02,\n",
            "          -5.4181e-02, -1.1219e-01],\n",
            "         [-2.3530e-03, -5.6685e-02, -2.7312e-01,  ..., -6.3166e-03,\n",
            "          -8.3245e-02, -1.4554e-01],\n",
            "         [-8.5701e-02,  4.3761e-02, -2.0563e-01,  ..., -7.6761e-02,\n",
            "           1.7886e-02, -1.2673e-01],\n",
            "         ...,\n",
            "         [-3.5857e-02, -3.7709e-02, -1.3556e-01,  ..., -1.7461e-02,\n",
            "           2.3406e-02, -1.3181e-01],\n",
            "         [ 3.9815e-02, -5.8227e-02, -2.8616e-01,  ...,  3.0946e-02,\n",
            "           4.0748e-02, -1.7510e-01],\n",
            "         [-3.7038e-02,  1.3488e-02, -2.8977e-01,  ...,  6.3683e-02,\n",
            "           5.1196e-04, -1.0940e-01]],\n",
            "\n",
            "        [[ 1.0692e-01, -1.4714e-01, -1.4119e-01,  ..., -1.0678e-01,\n",
            "          -4.4688e-02, -1.2618e-01],\n",
            "         [-8.9707e-03,  7.3714e-02, -1.8834e-01,  ..., -2.2327e-02,\n",
            "           6.7358e-02, -1.4982e-01],\n",
            "         [ 4.4143e-02, -1.6411e-01, -1.7034e-01,  ...,  7.6885e-02,\n",
            "           6.9320e-02, -1.1730e-01],\n",
            "         ...,\n",
            "         [ 4.3309e-03,  8.2815e-02, -1.2961e-01,  ..., -1.1640e-03,\n",
            "           2.0530e-01, -6.2341e-02],\n",
            "         [ 3.5808e-02, -3.3080e-02, -1.3560e-01,  ...,  5.0407e-02,\n",
            "           1.0244e-01, -1.4002e-01],\n",
            "         [-1.5305e-02,  9.7471e-03, -3.2805e-01,  ...,  7.9075e-02,\n",
            "          -5.4618e-02, -1.7369e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-5.9492e-02,  1.5720e-01, -1.5830e-01,  ...,  1.9487e-02,\n",
            "          -8.9087e-03, -1.8209e-01],\n",
            "         [-6.1264e-02, -1.1756e-02, -2.6257e-01,  ..., -8.5485e-02,\n",
            "           4.5739e-02, -1.4764e-01],\n",
            "         [-1.8213e-02,  5.8475e-02, -1.6849e-01,  ..., -5.0355e-02,\n",
            "          -6.6985e-02, -2.5637e-01],\n",
            "         ...,\n",
            "         [ 5.3596e-02, -1.1066e-01, -2.2224e-01,  ...,  2.0323e-01,\n",
            "          -1.9027e-02, -7.6929e-02],\n",
            "         [ 4.7396e-02, -1.3571e-01, -3.3262e-01,  ...,  3.5086e-02,\n",
            "           7.2856e-02, -2.7643e-01],\n",
            "         [ 2.9596e-02,  7.6100e-02, -2.5849e-01,  ...,  4.8725e-02,\n",
            "           7.5714e-03, -2.3794e-01]],\n",
            "\n",
            "        [[-5.7554e-02, -1.5372e-01, -1.3941e-01,  ..., -1.8484e-02,\n",
            "           3.9702e-03, -2.2791e-01],\n",
            "         [ 3.6486e-02, -9.6913e-02, -2.1424e-01,  ...,  3.2046e-02,\n",
            "          -1.4346e-01, -1.7507e-01],\n",
            "         [-8.5403e-02,  8.3579e-02, -2.0098e-01,  ...,  4.7362e-02,\n",
            "           2.1068e-02, -1.7142e-01],\n",
            "         ...,\n",
            "         [ 6.0758e-03, -2.6640e-02, -2.4368e-01,  ...,  5.6345e-02,\n",
            "          -2.2281e-02, -1.5176e-01],\n",
            "         [-1.3336e-02,  2.7534e-02, -1.6074e-01,  ...,  1.2308e-01,\n",
            "           8.7720e-02, -2.8767e-01],\n",
            "         [ 2.2297e-02, -1.6663e-01, -2.4525e-01,  ...,  3.4472e-02,\n",
            "           1.2005e-01, -2.0306e-01]],\n",
            "\n",
            "        [[ 6.7283e-02,  2.9881e-02, -2.6522e-01,  ...,  1.0744e-01,\n",
            "           1.5140e-01, -6.3527e-02],\n",
            "         [-8.8224e-02, -8.4465e-03, -1.2463e-01,  ...,  5.1457e-02,\n",
            "          -4.0018e-03, -1.2169e-01],\n",
            "         [ 4.2119e-02, -2.3379e-01, -1.2525e-01,  ...,  2.7900e-01,\n",
            "          -1.8287e-02, -1.4700e-01],\n",
            "         ...,\n",
            "         [-2.1166e-02, -3.8373e-02, -1.7287e-01,  ...,  1.0699e-01,\n",
            "          -7.4181e-02, -2.1996e-01],\n",
            "         [-3.7857e-02,  5.2654e-02, -1.9689e-01,  ...,  7.7040e-02,\n",
            "           4.0155e-02, -2.3333e-01],\n",
            "         [ 4.4707e-02,  1.2829e-01, -2.0804e-01,  ...,  9.0238e-02,\n",
            "           6.6720e-02, -1.6930e-01]]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "torch.Size([16, 556])\n",
            "torch.Size([8912, 6969])\n",
            "torch.Size([8896])\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Expected input batch_size (8912) to match target batch_size (8896).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[65], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,NUM_EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      5\u001b[0m   start_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[0;32m----> 6\u001b[0m   train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m   end_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m      8\u001b[0m   val_loss \u001b[38;5;241m=\u001b[39m evaluate(transformer)\n",
            "Cell \u001b[0;32mIn[64], line 33\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(logits\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(tgt_out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 33\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtgt_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Back propagation, calculating the gradients\u001b[39;00m\n\u001b[1;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (8912) to match target batch_size (8896)."
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "for epoch in range(1,NUM_EPOCHS+1):\n",
        "  start_time = timer()\n",
        "  train_loss = train_epoch(transformer, optimizer)\n",
        "  end_time = timer()\n",
        "  val_loss = evaluate(transformer)\n",
        "  print(f'Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}')\n",
        "  print(f'Epoch time: {(end_time - start_time):.3f}s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Nh0p7PyNoXX7"
      },
      "outputs": [],
      "source": [
        "# A function to generate the output sequence autoregressively using the greedy decoder algorithm\n",
        "# Usually, we would utilize something like beam search\n",
        "def greedy_decode(model, src, max_len, start_symbol):\n",
        "  src = src.to(DEVICE)\n",
        "  memory = model.encode(src.view(1,-1), None)\n",
        "  memory = memory.to(DEVICE)\n",
        "  ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "  for i in range(max_len-1):\n",
        "      out = model.decode(ys.view(1,-1), memory, None)\n",
        "      prob = nn.functional.softmax(model.generator(out[:, -1]),dim=1)\n",
        "      _, next_word = torch.max(prob, dim=1)\n",
        "      next_word = next_word.item()\n",
        "\n",
        "      ys = torch.cat([ys,torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "      if next_word == EOS_IDX:\n",
        "          break\n",
        "  return ys\n",
        "\n",
        "# Function for translation\n",
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "  model.eval()\n",
        "  src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
        "  num_tokens = src.shape[0]\n",
        "  tgt_tokens = greedy_decode(model,  src, max_len=num_tokens + 5, start_symbol=SOS_IDX).flatten()\n",
        "  return \" \".join(vocabularies[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<sos>\", \"\").replace(\"<eos>\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EGcMx_GL5MNl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "( def \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Trying to translate from English to Python\n",
        "print(translate(transformer, \"Give me a function to add 3 numbers.\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
