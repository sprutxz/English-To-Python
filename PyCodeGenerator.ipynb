{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sprutxz/English-To-Python/blob/main/PyCodeGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xSdUCIuxC2kc"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#import seaborn as sns\n",
        "from timeit import default_timer as timer\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator, vocab\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from tokenize import tokenize, untokenize\n",
        "import io\n",
        "import re\n",
        "#from nltk.stem import PorterStemmer\n",
        "\n",
        "# Setting the device for model\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#custom tokenizer for python code\n",
        "def tgt_tokenizer(python_code_str):\n",
        "    python_tokens = list(tokenize(io.BytesIO(python_code_str.encode('utf-8')).readline))\n",
        "    tokenized_output = []\n",
        "    for i in range(1, len(python_tokens)):\n",
        "        tokenized_output.append(python_tokens[i].string)\n",
        "    return tokenized_output\n",
        "\n",
        "src_tokenizer = get_tokenizer('spacy',language='en_core_web_sm') #tokenizer function for the english text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "39OhkMrlDaSH"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>solution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python program to add two numbers</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provid...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n\\tsum = num1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a program to find and print the largest ...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the smallest...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>write a python function to merge two given lis...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n\\treturn l1 + l2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4438</th>\n",
              "      <td>write a program to print bit wise and of two n...</td>\n",
              "      <td>a = 60            # 60 = 0011 1100\\nb = 13    ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4439</th>\n",
              "      <td>write a program to print bit wise or of two nu...</td>\n",
              "      <td>a = 60\\nb = 13\\nc = a | b\\nprint(\"OR\", c)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4440</th>\n",
              "      <td>write a program to print bit wise xor of two n...</td>\n",
              "      <td>a = 60\\nb = 13\\nc = a ^ b\\nprint(\"XOR\", c)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4441</th>\n",
              "      <td>write a program to calculate binary ones compl...</td>\n",
              "      <td>a = 60\\nc = ~a\\nprint(\"Binary Ones Complement\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4442</th>\n",
              "      <td>write a program to binary left shift a number</td>\n",
              "      <td>c = a &lt;&lt; 2\\nprint(\"Binary Left Shift\", c)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4443 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               question  \\\n",
              "0             write a python program to add two numbers   \n",
              "1     write a python function to add two user provid...   \n",
              "2     write a program to find and print the largest ...   \n",
              "3     write a program to find and print the smallest...   \n",
              "4     write a python function to merge two given lis...   \n",
              "...                                                 ...   \n",
              "4438  write a program to print bit wise and of two n...   \n",
              "4439  write a program to print bit wise or of two nu...   \n",
              "4440  write a program to print bit wise xor of two n...   \n",
              "4441  write a program to calculate binary ones compl...   \n",
              "4442      write a program to binary left shift a number   \n",
              "\n",
              "                                               solution  \n",
              "0     num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...  \n",
              "1     def add_two_numbers(num1, num2):\\n\\tsum = num1...  \n",
              "2     num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >= n...  \n",
              "3     num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...  \n",
              "4            def merge_lists(l1, l2):\\n\\treturn l1 + l2  \n",
              "...                                                 ...  \n",
              "4438  a = 60            # 60 = 0011 1100\\nb = 13    ...  \n",
              "4439          a = 60\\nb = 13\\nc = a | b\\nprint(\"OR\", c)  \n",
              "4440         a = 60\\nb = 13\\nc = a ^ b\\nprint(\"XOR\", c)  \n",
              "4441  a = 60\\nc = ~a\\nprint(\"Binary Ones Complement\"...  \n",
              "4442          c = a << 2\\nprint(\"Binary Left Shift\", c)  \n",
              "\n",
              "[4443 rows x 2 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating a Regular Expression (Regex) pattern of urls to remove them\n",
        "url_pattern = re.compile(r\"https?://\\S+\")\n",
        "\n",
        "src_doc = []\n",
        "tgt_doc = []\n",
        "\n",
        "i = 0\n",
        "# Making a dataset\n",
        "with open('english_python_data.txt',\"r\") as data_file:\n",
        "  data_lines = data_file.readlines()\n",
        "  dps = [] # List of dictionaries\n",
        "  dp = None # The current problem and solution\n",
        "  for line in data_lines:\n",
        "    if line[0] == \"#\":\n",
        "      tab_count = 0\n",
        "      loop_indent = 0\n",
        "      dict = {0: 0}\n",
        "      if dp:\n",
        "        dp['solution'] = ''.join(dp['solution'])\n",
        "        dp['solution'] = re.sub(r'\\n+', '\\n', dp['solution']) #replaces multiple newlines with a single newline\n",
        "        dp['solution'] = re.sub(r'(\\n\\t*)*$', '', dp['solution']) #removes any newlines at the end of the solution\n",
        "        dp['solution'] = re.sub(r'^\\n', '', dp['solution']) #removes any newlines at the beginning of the solution\n",
        "          \n",
        "        tgt_doc.append(tgt_tokenizer(dp['solution']))  \n",
        "        dps.append(dp)\n",
        "      dp = {\"question\": None, \"solution\": []}\n",
        "      dp['question'] = line[1:].strip(\"\\n \") # Removing any \\n in the question\n",
        "      dp['question'] = re.sub(r'^\\d+ ', \"\", dp['question']) # If the question starts with numbers, I remove them.\n",
        "      dp['question'] = url_pattern.sub('',dp['question']) # Replacing any urls\n",
        "      dp['question'] = dp['question'].lower() # lowercasing the question\n",
        "      dp['question'] = re.sub(r\"([.!?])\",\"\",dp['question']) # removing any punctuation\n",
        "      src_doc.append(src_tokenizer(dp['question'])) # Splitting the question into words\n",
        "    else:\n",
        "      line = re.sub(r'( |\\t)*\\n( |\\t)*', '\\n', line) #replaces spaces before a newline with a  just a newline\n",
        "      line = re.sub(r'^ #', '#', line)\n",
        "      if line == '\\n':\n",
        "        continue\n",
        "      \n",
        "      space_count = len(line) - len(line.lstrip(' '))\n",
        "      if loop_indent > space_count:\n",
        "        tab_count = dict[space_count]\n",
        "        loop_indent = space_count\n",
        "      if(len(dp['solution'])!=0):\n",
        "        if (bool(re.search(r':\\n$', dp['solution'][-1]))):\n",
        "          dict[space_count] = tab_count\n",
        "          loop_indent = space_count\n",
        "\n",
        "      \n",
        "      if tab_count > 0 and bool(re.search(r',\\n', dp['solution'][-1])!=True) and bool(re.search(fr'^(\\t){{{tab_count}}}', line))!=True:\n",
        "        line = re.sub(r'^ *', '\\t'*tab_count, line)#replaces the first space with a tab\n",
        "      \n",
        "      if re.search(r'^(if|else|elif|for|while|def|class|try|except|finally|with)', line):\n",
        "        tab_count += 1\n",
        "      \n",
        "      \n",
        "      dp['solution'].append(line)\n",
        "      \n",
        "\n",
        "# converting the data to a table for easier viewing\n",
        "dataset = pd.DataFrame(dps)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1 = pd.read_csv('dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Problem</th>\n",
              "      <th>Python Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Write a NumPy program to repeat elements of an...</td>\n",
              "      <td>import numpy as np\\rx = np.repeat(3, 4)\\rprint...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Write a Python function to create and print a ...</td>\n",
              "      <td>def printValues():\\n\\tl = list()\\n\\tfor i in r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Write a Python program to remove duplicates fr...</td>\n",
              "      <td>import itertools\\rnum = [[10, 20], [40], [30, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Write a NumPy program to compute the x and y c...</td>\n",
              "      <td>import numpy as np\\rimport matplotlib.pyplot a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Write a Python program to alter a given SQLite...</td>\n",
              "      <td>import sqlite3\\rfrom sqlite3 import Error\\rdef...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3302</th>\n",
              "      <td>Python Program to Check Whether a Number is Po...</td>\n",
              "      <td>\\nn=int(input(\"Enter number: \"))\\nif(n&gt;0):\\n ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3303</th>\n",
              "      <td>\\nThe Fibonacci Sequence is computed based on ...</td>\n",
              "      <td>\\ndef f(n):\\n    if n == 0: return 0\\n    elif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3304</th>\n",
              "      <td>\\n\\n\\nPlease raise a RuntimeError exception.\\n:</td>\n",
              "      <td>\\nraise RuntimeError('something wrong')\\n\\n\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3305</th>\n",
              "      <td>Program to print inverted right triangle alpha...</td>\n",
              "      <td>\\nprint(\"Enter the row and column size:\");\\nro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3306</th>\n",
              "      <td>Program to find the sum of series 1+X+X^2/2......</td>\n",
              "      <td>\\nprint(\"Enter the range of number:\")\\nn=int(i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3307 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Problem  \\\n",
              "0     Write a NumPy program to repeat elements of an...   \n",
              "1     Write a Python function to create and print a ...   \n",
              "2     Write a Python program to remove duplicates fr...   \n",
              "3     Write a NumPy program to compute the x and y c...   \n",
              "4     Write a Python program to alter a given SQLite...   \n",
              "...                                                 ...   \n",
              "3302  Python Program to Check Whether a Number is Po...   \n",
              "3303  \\nThe Fibonacci Sequence is computed based on ...   \n",
              "3304    \\n\\n\\nPlease raise a RuntimeError exception.\\n:   \n",
              "3305  Program to print inverted right triangle alpha...   \n",
              "3306  Program to find the sum of series 1+X+X^2/2......   \n",
              "\n",
              "                                            Python Code  \n",
              "0     import numpy as np\\rx = np.repeat(3, 4)\\rprint...  \n",
              "1     def printValues():\\n\\tl = list()\\n\\tfor i in r...  \n",
              "2     import itertools\\rnum = [[10, 20], [40], [30, ...  \n",
              "3     import numpy as np\\rimport matplotlib.pyplot a...  \n",
              "4     import sqlite3\\rfrom sqlite3 import Error\\rdef...  \n",
              "...                                                 ...  \n",
              "3302  Â \\nn=int(input(\"Enter number: \"))\\nif(n>0):\\n ...  \n",
              "3303  \\ndef f(n):\\n    if n == 0: return 0\\n    elif...  \n",
              "3304    \\nraise RuntimeError('something wrong')\\n\\n\\n\\n  \n",
              "3305  \\nprint(\"Enter the row and column size:\");\\nro...  \n",
              "3306  \\nprint(\"Enter the range of number:\")\\nn=int(i...  \n",
              "\n",
              "[3307 rows x 2 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = pd.read_csv('ProblemSolutionPythonV3.csv')\n",
        "df2 = df2.drop('Unnamed: 0', axis=1)\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>solution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Write a NumPy program to repeat elements of an...</td>\n",
              "      <td>import numpy as np\\rx = np.repeat(3, 4)\\rprint...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Write a Python function to create and print a ...</td>\n",
              "      <td>def printValues():\\n\\tl = list()\\n\\tfor i in r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Write a Python program to remove duplicates fr...</td>\n",
              "      <td>import itertools\\rnum = [[10, 20], [40], [30, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Write a NumPy program to compute the x and y c...</td>\n",
              "      <td>import numpy as np\\rimport matplotlib.pyplot a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Write a Python program to alter a given SQLite...</td>\n",
              "      <td>import sqlite3\\rfrom sqlite3 import Error\\rdef...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3302</th>\n",
              "      <td>Python Program to Check Whether a Number is Po...</td>\n",
              "      <td>\\nn=int(input(\"Enter number: \"))\\nif(n&gt;0):\\n ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3303</th>\n",
              "      <td>\\nThe Fibonacci Sequence is computed based on ...</td>\n",
              "      <td>\\ndef f(n):\\n    if n == 0: return 0\\n    elif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3304</th>\n",
              "      <td>\\n\\n\\nPlease raise a RuntimeError exception.\\n:</td>\n",
              "      <td>\\nraise RuntimeError('something wrong')\\n\\n\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3305</th>\n",
              "      <td>Program to print inverted right triangle alpha...</td>\n",
              "      <td>\\nprint(\"Enter the row and column size:\");\\nro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3306</th>\n",
              "      <td>Program to find the sum of series 1+X+X^2/2......</td>\n",
              "      <td>\\nprint(\"Enter the range of number:\")\\nn=int(i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3307 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               question  \\\n",
              "0     Write a NumPy program to repeat elements of an...   \n",
              "1     Write a Python function to create and print a ...   \n",
              "2     Write a Python program to remove duplicates fr...   \n",
              "3     Write a NumPy program to compute the x and y c...   \n",
              "4     Write a Python program to alter a given SQLite...   \n",
              "...                                                 ...   \n",
              "3302  Python Program to Check Whether a Number is Po...   \n",
              "3303  \\nThe Fibonacci Sequence is computed based on ...   \n",
              "3304    \\n\\n\\nPlease raise a RuntimeError exception.\\n:   \n",
              "3305  Program to print inverted right triangle alpha...   \n",
              "3306  Program to find the sum of series 1+X+X^2/2......   \n",
              "\n",
              "                                               solution  \n",
              "0     import numpy as np\\rx = np.repeat(3, 4)\\rprint...  \n",
              "1     def printValues():\\n\\tl = list()\\n\\tfor i in r...  \n",
              "2     import itertools\\rnum = [[10, 20], [40], [30, ...  \n",
              "3     import numpy as np\\rimport matplotlib.pyplot a...  \n",
              "4     import sqlite3\\rfrom sqlite3 import Error\\rdef...  \n",
              "...                                                 ...  \n",
              "3302  Â \\nn=int(input(\"Enter number: \"))\\nif(n>0):\\n ...  \n",
              "3303  \\ndef f(n):\\n    if n == 0: return 0\\n    elif...  \n",
              "3304    \\nraise RuntimeError('something wrong')\\n\\n\\n\\n  \n",
              "3305  \\nprint(\"Enter the row and column size:\");\\nro...  \n",
              "3306  \\nprint(\"Enter the range of number:\")\\nn=int(i...  \n",
              "\n",
              "[3307 rows x 2 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = df2.rename(columns={\"Problem\": \"question\", \"Python Code\": \"solution\"})\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>solution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python program to add two numbers</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provid...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n\\tsum = num1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a program to find and print the largest ...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the smallest...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>write a python function to merge two given lis...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n\\treturn l1 + l2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7745</th>\n",
              "      <td>Python Program to Check Whether a Number is Po...</td>\n",
              "      <td>\\nn=int(input(\"Enter number: \"))\\nif(n&gt;0):\\n ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7746</th>\n",
              "      <td>\\nThe Fibonacci Sequence is computed based on ...</td>\n",
              "      <td>\\ndef f(n):\\n    if n == 0: return 0\\n    elif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7747</th>\n",
              "      <td>\\n\\n\\nPlease raise a RuntimeError exception.\\n:</td>\n",
              "      <td>\\nraise RuntimeError('something wrong')\\n\\n\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7748</th>\n",
              "      <td>Program to print inverted right triangle alpha...</td>\n",
              "      <td>\\nprint(\"Enter the row and column size:\");\\nro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7749</th>\n",
              "      <td>Program to find the sum of series 1+X+X^2/2......</td>\n",
              "      <td>\\nprint(\"Enter the range of number:\")\\nn=int(i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7750 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               question  \\\n",
              "0             write a python program to add two numbers   \n",
              "1     write a python function to add two user provid...   \n",
              "2     write a program to find and print the largest ...   \n",
              "3     write a program to find and print the smallest...   \n",
              "4     write a python function to merge two given lis...   \n",
              "...                                                 ...   \n",
              "7745  Python Program to Check Whether a Number is Po...   \n",
              "7746  \\nThe Fibonacci Sequence is computed based on ...   \n",
              "7747    \\n\\n\\nPlease raise a RuntimeError exception.\\n:   \n",
              "7748  Program to print inverted right triangle alpha...   \n",
              "7749  Program to find the sum of series 1+X+X^2/2......   \n",
              "\n",
              "                                               solution  \n",
              "0     num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...  \n",
              "1     def add_two_numbers(num1, num2):\\n\\tsum = num1...  \n",
              "2     num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >= n...  \n",
              "3     num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...  \n",
              "4            def merge_lists(l1, l2):\\n\\treturn l1 + l2  \n",
              "...                                                 ...  \n",
              "7745  Â \\nn=int(input(\"Enter number: \"))\\nif(n>0):\\n ...  \n",
              "7746  \\ndef f(n):\\n    if n == 0: return 0\\n    elif...  \n",
              "7747    \\nraise RuntimeError('something wrong')\\n\\n\\n\\n  \n",
              "7748  \\nprint(\"Enter the row and column size:\");\\nro...  \n",
              "7749  \\nprint(\"Enter the range of number:\")\\nn=int(i...  \n",
              "\n",
              "[7750 rows x 2 columns]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "combined_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "1000\n",
            "1001\n",
            "1002\n",
            "1003\n",
            "1004\n",
            "1005\n",
            "1006\n",
            "1007\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1015\n",
            "1016\n",
            "1017\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1021\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1036\n",
            "1037\n",
            "1038\n",
            "1039\n",
            "1040\n",
            "1041\n",
            "1042\n",
            "1043\n",
            "1044\n",
            "1045\n",
            "1046\n",
            "1047\n",
            "1048\n",
            "1049\n",
            "1050\n",
            "1051\n",
            "1052\n",
            "1053\n",
            "1054\n",
            "1055\n",
            "1056\n",
            "1057\n",
            "1058\n",
            "1059\n",
            "1060\n",
            "1061\n",
            "1062\n",
            "1063\n",
            "1064\n",
            "1065\n",
            "1066\n",
            "1067\n",
            "1068\n",
            "1069\n",
            "1070\n",
            "1071\n",
            "1072\n",
            "1073\n",
            "1074\n",
            "1075\n",
            "1076\n",
            "1077\n",
            "1078\n",
            "1079\n",
            "1080\n",
            "1081\n",
            "1082\n",
            "1083\n",
            "1084\n",
            "1085\n",
            "1086\n",
            "1087\n",
            "1088\n",
            "1089\n",
            "1090\n",
            "1091\n",
            "1092\n",
            "1093\n",
            "1094\n",
            "1095\n",
            "1096\n",
            "1097\n",
            "1098\n",
            "1099\n",
            "1100\n",
            "1101\n",
            "1102\n",
            "1103\n",
            "1104\n",
            "1105\n",
            "1106\n",
            "1107\n",
            "1108\n",
            "1109\n",
            "1110\n",
            "1111\n",
            "1112\n",
            "1113\n",
            "1114\n",
            "1115\n",
            "1116\n",
            "1117\n",
            "1118\n",
            "1119\n",
            "1120\n",
            "1121\n",
            "1122\n",
            "1123\n",
            "1124\n",
            "1125\n",
            "1126\n",
            "1127\n",
            "1128\n",
            "1129\n",
            "1130\n",
            "1131\n",
            "1132\n",
            "1133\n",
            "1134\n",
            "1135\n",
            "1136\n",
            "1137\n",
            "1138\n",
            "1139\n",
            "1140\n",
            "1141\n",
            "1142\n",
            "1143\n",
            "1144\n",
            "1145\n",
            "1146\n",
            "1147\n",
            "1148\n",
            "1149\n",
            "1150\n",
            "1151\n",
            "1152\n",
            "1153\n",
            "1154\n",
            "1155\n",
            "1156\n",
            "1157\n",
            "1158\n",
            "1159\n",
            "1160\n",
            "1161\n",
            "1162\n",
            "1163\n",
            "1164\n",
            "1165\n",
            "1166\n",
            "1167\n",
            "1168\n",
            "1169\n",
            "1170\n",
            "1171\n",
            "1172\n",
            "1173\n",
            "1174\n",
            "1175\n",
            "1176\n",
            "1177\n",
            "1178\n",
            "1179\n",
            "1180\n",
            "1181\n",
            "1182\n",
            "1183\n",
            "1184\n",
            "1185\n",
            "1186\n",
            "1187\n",
            "1188\n",
            "1189\n",
            "1190\n",
            "1191\n",
            "1192\n",
            "1193\n",
            "1194\n",
            "1195\n",
            "1196\n",
            "1197\n",
            "1198\n",
            "1199\n",
            "1200\n",
            "1201\n",
            "1202\n",
            "1203\n",
            "1204\n",
            "1205\n",
            "1206\n",
            "1207\n",
            "1208\n",
            "1209\n",
            "1210\n",
            "1211\n",
            "1212\n",
            "1213\n",
            "1214\n",
            "1215\n",
            "1216\n",
            "1217\n",
            "1218\n",
            "1219\n",
            "1220\n",
            "1221\n",
            "1222\n",
            "1223\n",
            "1224\n",
            "1225\n",
            "1226\n",
            "1227\n",
            "1228\n",
            "1229\n",
            "1230\n",
            "1231\n",
            "1232\n",
            "1233\n",
            "1234\n",
            "1235\n",
            "1236\n",
            "1237\n",
            "1238\n",
            "1239\n",
            "1240\n",
            "1241\n",
            "1242\n",
            "1243\n",
            "1244\n",
            "1245\n",
            "1246\n",
            "1247\n",
            "1248\n",
            "1249\n",
            "1250\n",
            "1251\n",
            "1252\n",
            "1253\n",
            "1254\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "8",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[33], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m space_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(line\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop_indent \u001b[38;5;241m>\u001b[39m space_count:\n\u001b[0;32m---> 65\u001b[0m   tab_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mspace_count\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     66\u001b[0m   loop_indent \u001b[38;5;241m=\u001b[39m space_count\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(dp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolution\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n",
            "\u001b[0;31mKeyError\u001b[0m: 8"
          ]
        }
      ],
      "source": [
        "# Creating a Regular Expression (Regex) pattern of urls to remove them\n",
        "url_pattern = re.compile(r\"https?://\\S+\")\n",
        "\n",
        "src_doc = []\n",
        "tgt_doc = []\n",
        "\n",
        "i = 0\n",
        "# Making a dataset\n",
        "with open('ProblemSolutionPythonV3.txt',\"r\") as data_file:\n",
        "  data_lines = data_file.readlines()\n",
        "  dps = [] # List of dictionaries\n",
        "  dp = None # The current problem and solution\n",
        "  problem = False\n",
        "  solution = False\n",
        "  q_count = 0 \n",
        "  \n",
        "  for line in data_lines:\n",
        "    if re.search(r'PROBLEM', line):\n",
        "      problem = True\n",
        "      solution = False\n",
        "      \n",
        "      if dp and len(dp['solution']) != 0:\n",
        "        dp['solution'] = ''.join(dp['solution'])\n",
        "        dp['solution'] = re.sub(r'\\n+', '\\n', dp['solution']) #replaces multiple newlines with a single newline\n",
        "        dp['solution'] = re.sub(r'(\\n\\t*)*$', '', dp['solution']) #removes any newlines at the end of the solution\n",
        "        dp['solution'] = re.sub(r'^\\n', '', dp['solution']) #removes any newlines at the beginning of the solution\n",
        "        dp['question'] = ''.join(dp['question'])\n",
        "          \n",
        "        tgt_doc.append(tgt_tokenizer(dp['solution']))  \n",
        "        dps.append(dp)\n",
        "        \n",
        "      dp = {\"question\": [], \"solution\": []}\n",
        "      q_count += 1\n",
        "      print(q_count)\n",
        "      continue\n",
        "    \n",
        "    elif re.search(r'PYTHON CODE', line):\n",
        "      problem = False\n",
        "      solution = True\n",
        "      \n",
        "      tab_count = 0\n",
        "      loop_indent = 0\n",
        "      dict = {0: 0}\n",
        "      continue\n",
        "    \n",
        "    if problem:\n",
        "      \n",
        "      line = line.strip(\"\\n \") # Removing any \\n in the question\n",
        "      line = re.sub(r'^d+ ', \"\", line) # If the question starts with numbers, I remove them.\n",
        "      line = url_pattern.sub('',line) # Replacing any urls\n",
        "      line = line.lower() # lowercasing the question\n",
        "      line = re.sub(r\"([.!?])\",\"\",line) # removing any punctuation\n",
        "      dp['question'].append(line)\n",
        "      src_doc.append(src_tokenizer(line)) # Splitting the question into words\n",
        "      \n",
        "    \n",
        "    else: \n",
        "      line = re.sub(r'( |\\t)*\\n( |\\t)*', '\\n', line) #replaces spaces before a newline with a  just a newline\n",
        "      line = re.sub(r'^ #', '#', line)\n",
        "      if line == '\\n':\n",
        "        continue\n",
        "      \n",
        "      space_count = len(line) - len(line.lstrip(' '))\n",
        "      if loop_indent > space_count:\n",
        "        tab_count = dict[space_count]\n",
        "        loop_indent = space_count\n",
        "      if(len(dp['solution'])!=0):\n",
        "        if (bool(re.search(r':\\n$', dp['solution'][-1]))):\n",
        "          dict[space_count] = tab_count\n",
        "          loop_indent = space_count\n",
        "\n",
        "      \n",
        "      if tab_count > 0 and bool(re.search(r',\\n', dp['solution'][-1])!=True) and bool(re.search(fr'^(\\t){{{tab_count}}}', line))!=True:\n",
        "        line = re.sub(r'^ *', '\\t'*tab_count, line)#replaces the first space with a tab\n",
        "      \n",
        "      if re.search(r'^(if|else|elif|for|while|def|class|try|except|finally|with)', line):\n",
        "        tab_count += 1\n",
        "      \n",
        "      \n",
        "      dp['solution'].append(line)\n",
        "      \n",
        "\n",
        "# converting the data to a table for easier viewing\n",
        "dataset = pd.DataFrame(dps)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.save('data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>solution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python program to add two numbers</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provid...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n\\tsum = num1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a program to find and print the largest ...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the smallest...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>write a python function to merge two given lis...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n\\treturn l1 + l2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4438</th>\n",
              "      <td>write a program to print bit wise and of two n...</td>\n",
              "      <td>a = 60            # 60 = 0011 1100\\nb = 13    ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4439</th>\n",
              "      <td>write a program to print bit wise or of two nu...</td>\n",
              "      <td>a = 60\\nb = 13\\nc = a | b\\nprint(\"OR\", c)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4440</th>\n",
              "      <td>write a program to print bit wise xor of two n...</td>\n",
              "      <td>a = 60\\nb = 13\\nc = a ^ b\\nprint(\"XOR\", c)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4441</th>\n",
              "      <td>write a program to calculate binary ones compl...</td>\n",
              "      <td>a = 60\\nc = ~a\\nprint(\"Binary Ones Complement\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4442</th>\n",
              "      <td>write a program to binary left shift a number</td>\n",
              "      <td>c = a &lt;&lt; 2\\nprint(\"Binary Left Shift\", c)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4443 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               question  \\\n",
              "0             write a python program to add two numbers   \n",
              "1     write a python function to add two user provid...   \n",
              "2     write a program to find and print the largest ...   \n",
              "3     write a program to find and print the smallest...   \n",
              "4     write a python function to merge two given lis...   \n",
              "...                                                 ...   \n",
              "4438  write a program to print bit wise and of two n...   \n",
              "4439  write a program to print bit wise or of two nu...   \n",
              "4440  write a program to print bit wise xor of two n...   \n",
              "4441  write a program to calculate binary ones compl...   \n",
              "4442      write a program to binary left shift a number   \n",
              "\n",
              "                                               solution  \n",
              "0     num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...  \n",
              "1     def add_two_numbers(num1, num2):\\n\\tsum = num1...  \n",
              "2     num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >= n...  \n",
              "3     num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...  \n",
              "4            def merge_lists(l1, l2):\\n\\treturn l1 + l2  \n",
              "...                                                 ...  \n",
              "4438  a = 60            # 60 = 0011 1100\\nb = 13    ...  \n",
              "4439          a = 60\\nb = 13\\nc = a | b\\nprint(\"OR\", c)  \n",
              "4440         a = 60\\nb = 13\\nc = a ^ b\\nprint(\"XOR\", c)  \n",
              "4441  a = 60\\nc = ~a\\nprint(\"Binary Ones Complement\"...  \n",
              "4442          c = a << 2\\nprint(\"Binary Left Shift\", c)  \n",
              "\n",
              "[4443 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = pd.read_csv('dataset.csv')\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "src_emb = gensim.models.Word2Vec.load(\"src_emb.model\") # Loading the source language model\n",
        "tgt_emb = gensim.models.Word2Vec.load(\"tgt_emb.model\") # Loading the target language model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.04950405 -0.13013975  0.29322964  0.26577362 -0.0580922  -0.13931315\n",
            " -0.06955359  0.1276154  -0.28290156  0.43636248  0.35694352  0.07798368\n",
            "  0.25970683  0.10230417 -0.35744947 -0.06195316 -0.25638404  0.16395478\n",
            "  0.0283      0.0842226  -0.03871991  0.11544742  0.3074301  -0.18366054\n",
            "  0.0746874   0.13687396 -0.26305628  0.01998951 -0.285633   -0.38873056\n",
            " -0.20275687 -0.0852707   0.05183105 -0.24004063 -0.12636128 -0.0394831\n",
            " -0.05548012  0.27095413  0.69431627  0.02059945  0.01835858  0.21582782\n",
            "  0.1759899  -0.18655933  0.2607489  -0.19880332  0.11363642  0.07459424\n",
            " -0.1197295   0.250948   -0.04176089  0.29681596  0.03351113  0.14749613\n",
            "  0.17432393  0.04886602 -0.3666464  -0.31774977 -0.11895294 -0.02384274\n",
            "  0.04614635 -0.1843633  -0.27309445 -0.03571155]\n"
          ]
        }
      ],
      "source": [
        "word = \"a\"\n",
        "vector = src_emb.wv.get_vector(word)\n",
        "print(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating dictionaries for the tokenizers and the vocabularies\n",
        "SRC_LANGUAGE = 'en'\n",
        "TGT_LANGUAGE = 'python'\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3 # Tokens for Unknown, Padding, start of sentence, end of sentence\n",
        "vocabularies = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocabularies[SRC_LANGUAGE] = vocab(src_emb.wv.key_to_index, min_freq=0) # Creating a vocabulary for the source language\n",
        "vocabularies[TGT_LANGUAGE] = vocab(tgt_emb.wv.key_to_index, min_freq=0) # Creating a vocabulary for the target language\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "  vocabularies[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizers = {}\n",
        "tokenizers[SRC_LANGUAGE] = src_tokenizer # Creating a tokenizer for the source language\n",
        "tokenizers[TGT_LANGUAGE] = tgt_tokenizer # Creating a tokenizer for the target language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "l-4VEO2Oe25o"
      },
      "outputs": [],
      "source": [
        "# Positional Encoding module -> this class is the positional encoder (see above for details)\n",
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self,emb_size:int, dropout:float, maxlen:int = 5000):\n",
        "    super().__init__()\n",
        "    den = torch.exp(-torch.arange(0,emb_size,2)*math.log(10000) / emb_size)\n",
        "    pos = torch.arange(0,maxlen).reshape(maxlen,1)\n",
        "    pos_embedding = torch.zeros((maxlen,emb_size))\n",
        "    pos_embedding[:,0::2] = torch.sin(pos * den)\n",
        "    pos_embedding[:,1::2] = torch.cos(pos * den)\n",
        "    pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # Saving the positional encoding in the model state dict, but making sure PyTorch doesn't \"train\"\n",
        "    # these parameters because they don't need to be trained\n",
        "    self.register_buffer('pos_embedding',pos_embedding)\n",
        "\n",
        "  def forward(self,token_embedding: Tensor):\n",
        "    return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# # Converting the tokens into embeddings\n",
        "# class TokenEmbedding(nn.Module):\n",
        "#   def __init__(self,vocab_size: int, emb_size):\n",
        "#     super().__init__()\n",
        "#     self.embedding = nn.Embedding(vocab_size,emb_size)\n",
        "#     self.embed_size = emb_size\n",
        "\n",
        "#   def forward(self,tokens:Tensor):\n",
        "#     return self.embedding(tokens.long()) * math.sqrt(self.embed_size) # we multiply by square root of embedding size to scale. The Transformer paper mentions this.\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "  def __init__(self, vocab_size: int, emb_size: int, word2vec_model_path: str):\n",
        "    super().__init__()\n",
        "    self.word2vec_model = gensim.models.Word2Vec.load(word2vec_model_path)\n",
        "    self.embedding = nn.Embedding(vocab_size+4, emb_size)\n",
        "    self.embed_size = emb_size\n",
        "\n",
        "    # Initialize the embedding weights with the Word2Vec vectors\n",
        "    self.embedding.weight.data[4:].copy_(torch.from_numpy(self.word2vec_model.wv.vectors))\n",
        "\n",
        "  def forward(self, tokens: Tensor):\n",
        "    return self.embedding(tokens.long()) * math.sqrt(self.embed_size)\n",
        "  \n",
        "    \n",
        "\n",
        "# The Actual Model\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "  def __init__(self, num_encoder_layers:int, num_decoder_layers:int, emb_size:int, nhead:int, src_vocab_size:int, tgt_vocab_size:int, dim_feedforward: int=512, dropout:float = 0.1):\n",
        "    super().__init__()\n",
        "    self.transformer = Transformer(d_model=emb_size, nhead=nhead, num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers,dim_feedforward=dim_feedforward,dropout=dropout,\n",
        "                                      batch_first=True)\n",
        "    self.generator = nn.Linear(emb_size,tgt_vocab_size) # A layer to convert the matrix (seq_len, emb_size) to (seq_len, tgt_vocab_size)\n",
        "    self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size, \"src_emb.model\")\n",
        "    self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size,emb_size, \"tgt_emb.model\")\n",
        "\n",
        "    # Getting the positional encodings\n",
        "    self.positional_encoding = PositionalEncoding(emb_size,dropout=dropout)\n",
        "\n",
        "  def forward(self, src:Tensor, trg: Tensor, src_mask: Tensor, tgt_mask: Tensor, src_padding_mask: Tensor, tgt_padding_mask: Tensor,\n",
        "              memory_key_padding_mask: Tensor):\n",
        "\n",
        "    # Embedding both the input and output\n",
        "    src_embedding = self.positional_encoding(self.src_tok_emb(src))\n",
        "    tgt_embedding = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "\n",
        "    # Getting the output\n",
        "    output = self.transformer(src_embedding, tgt_embedding, src_mask, tgt_mask, None, src_padding_mask,tgt_padding_mask,memory_key_padding_mask)\n",
        "\n",
        "    # Getting the logits\n",
        "    return self.generator(output)\n",
        "  \n",
        "\n",
        "  # Encoding the input\n",
        "  def encode(self, src: Tensor, src_mask: Tensor):\n",
        "    embedding = self.positional_encoding(self.src_tok_emb(src))\n",
        "    encoder_output = self.transformer.encoder(embedding, src_mask)\n",
        "    return encoder_output\n",
        "\n",
        "  # Decoding the output\n",
        "  def decode(self,tgt:Tensor, memory: Tensor, tgt_mask:Tensor):\n",
        "    tgt_embedding = self.tgt_tok_emb(tgt)\n",
        "    return self.transformer.decoder(self.positional_encoding(tgt_embedding), memory, tgt_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-Teu_4Usi7Vl"
      },
      "outputs": [],
      "source": [
        "# Defining the lookahead mask that will prevent the model from looking ahead during training\n",
        "# Also need to define masks that will mask the padding tokens.\n",
        "# If we don't mask the padding tokens, the model will end up taking the values of the padding into account\n",
        "# into prediction\n",
        "\n",
        "# Generating the lookahead mask\n",
        "def generate_square_subsequent_mask(sz):\n",
        "  mask = (torch.triu(torch.ones((sz,sz),device=DEVICE)) == 1).transpose(0,1)\n",
        "  mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "  return mask\n",
        "\n",
        "# Creating the other mask\n",
        "def create_mask(src, tgt):\n",
        "  src_seq_len = src.shape[1]\n",
        "  tgt_seq_len = tgt.shape[1]\n",
        "\n",
        "  tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "  src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "  src_padding_mask = (src == PAD_IDX)\n",
        "  tgt_padding_mask = (tgt == PAD_IDX)\n",
        "  return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "qjIQzZENjLgw"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into training and testing\n",
        "#training, testing = train_test_split(dataset,test_size=0.2,random_state=42,shuffle=True)\n",
        "\n",
        "train_size = int(len(dataset)*0.8)\n",
        "test_size = len(dataset) - train_size\n",
        "training, testing = random_split(dataset,[train_size,test_size])\n",
        "\n",
        "# Running the data through a pipeline to get the transformed and prepared dataset\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "  def func(txt_input):\n",
        "    for transform in transforms:\n",
        "      txt_input = transform(txt_input)\n",
        "    return txt_input\n",
        "  return func\n",
        "\n",
        "# Function to add BOS/EOS and create tensor for input sequence indicies\n",
        "def tensor_transform(token_ids):\n",
        "  return torch.cat((torch.tensor([SOS_IDX]),torch.tensor(token_ids),torch.tensor([EOS_IDX])))\n",
        "\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "  text_transform[ln] = sequential_transforms(tokenizers[ln],vocabularies[ln],tensor_transform) # Tokenize, Convert to Indicies, then Add Special Tokens\n",
        "\n",
        "# function to put all the data samples into batches\n",
        "def collate_fn(batch):\n",
        "  src_batch, tgt_batch = [], []\n",
        "\n",
        "  # Iterating through the questions\n",
        "  for X in batch.dataset['question'].values:\n",
        "    token_tensor = text_transform[SRC_LANGUAGE](X.strip('\\n\\t'))\n",
        "    #token_tensor = token_tensor[:-1]\n",
        "    src_batch.append(token_tensor)\n",
        "\n",
        "  # Iterating through the solutions\n",
        "  for y in batch.dataset['solution'].values:\n",
        "    token_tensor = text_transform[TGT_LANGUAGE](y.strip('\\n\\t'))\n",
        "    #token_tensor = token_tensor[:-1]\n",
        "    tgt_batch.append(token_tensor)\n",
        "\n",
        "  src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "  tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "  return src_batch.T, tgt_batch.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "wZUdqI_WkrPp"
      },
      "outputs": [],
      "source": [
        "# Defining the model, loss function, and optimizer\n",
        "torch.manual_seed(10)\n",
        "\n",
        "SRC_VOCAB_SIZE = len(vocabularies[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocabularies[TGT_LANGUAGE])\n",
        "EMB_SIZE = 64\n",
        "NHEAD = 4\n",
        "FFN_HID_DIM = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "\n",
        "# Defining the model\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM).to(DEVICE)\n",
        "\n",
        "# Setting the parameters using the xavier uniform distribution\n",
        "for p in transformer.parameters():\n",
        "  if p.dim() > 1:\n",
        "    nn.init.xavier_uniform_(p)\n",
        "\n",
        "# Putting the model on GPU\n",
        "#transformer = transformer.to(DEVICE)\n",
        "\n",
        "# Defining the loss function\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_IDX) # makes sure that the padding token doesn't contribute to the loss function!\n",
        "\n",
        "# Defining the optimizer\n",
        "optimizer = optim.AdamW(transformer.parameters(),lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "21DZ5Z-Vkb0h"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model,optimizer):\n",
        "  # Setting the model to training mode\n",
        "  model.train()\n",
        "  losses = 0\n",
        "\n",
        "  # Preparing the data\n",
        "  X,y = collate_fn(training)\n",
        "  training_dataset = TensorDataset(X,y)\n",
        "  train_dataloader = DataLoader(training_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "  # Iterating through the data\n",
        "  for src, tgt in train_dataloader:\n",
        "    src = src.to(DEVICE)\n",
        "    tgt = tgt.to(DEVICE)\n",
        "    tgt_in = tgt[:,:-1]\n",
        "\n",
        "    # Getting the masks\n",
        "    src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_in)\n",
        "    logits = model(src,tgt_in, src_mask, tgt_mask, src_padding_mask,tgt_padding_mask,src_padding_mask) # memory is the encoder outputs\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    tgt_out = tgt[:,1:]\n",
        "    logits = logits.permute(0,2,1)\n",
        "    loss = loss_fn(logits,tgt_out)\n",
        "    loss.backward() # Back propagation, calculating the gradients\n",
        "\n",
        "    optimizer.step()\n",
        "    losses += loss.item()\n",
        "\n",
        "  return losses / len(list(train_dataloader)) # Getting the average loss per example\n",
        "\n",
        "# Evaluation Loop\n",
        "def evaluate(model):\n",
        "  model.eval()\n",
        "  losses = 0\n",
        "\n",
        "  # Preparing the data\n",
        "  X,y = collate_fn(testing)\n",
        "  testing_data = TensorDataset(X,y)\n",
        "  val_dataloader = DataLoader(testing_data, batch_size=BATCH_SIZE)\n",
        "\n",
        "  # Iterating through the data\n",
        "  for src, tgt in val_dataloader:\n",
        "    src = src.to(DEVICE)\n",
        "    tgt = tgt.to(DEVICE)\n",
        "\n",
        "    tgt_input = tgt[:,:-1] # Getting the sentence except the EOS since EOS is never inputted to decoder\n",
        "\n",
        "    # Getting the masks\n",
        "    src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "    logits = model(src,tgt_input, src_mask, tgt_mask, src_padding_mask,tgt_padding_mask,src_padding_mask) # memory is the encoder outputs\n",
        "    tgt_out = tgt[:,1:]\n",
        "    loss = loss_fn(logits.reshape(-1,logits.shape[-1]),tgt_out.reshape(-1))\n",
        "    losses += loss.item()\n",
        "\n",
        "  return losses / len(list(val_dataloader)) # Getting the average loss per example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/leroy/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[58], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,NUM_EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      5\u001b[0m   start_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[0;32m----> 6\u001b[0m   train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m   end_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m      8\u001b[0m   val_loss \u001b[38;5;241m=\u001b[39m evaluate(transformer)\n",
            "Cell \u001b[0;32mIn[57], line 28\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer)\u001b[0m\n\u001b[1;32m     25\u001b[0m   loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Back propagation, calculating the gradients\u001b[39;00m\n\u001b[1;32m     27\u001b[0m   optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 28\u001b[0m   losses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(train_dataloader))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "for epoch in range(1,NUM_EPOCHS+1):\n",
        "  start_time = timer()\n",
        "  train_loss = train_epoch(transformer, optimizer)\n",
        "  end_time = timer()\n",
        "  val_loss = evaluate(transformer)\n",
        "  print(f'Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}')\n",
        "  print(f'Epoch time: {(end_time - start_time):.3f}s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'transformer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transformer' is not defined"
          ]
        }
      ],
      "source": [
        "transformer.load_state_dict(torch.load('model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Nh0p7PyNoXX7"
      },
      "outputs": [],
      "source": [
        "# A function to generate the output sequence autoregressively using the greedy decoder algorithm\n",
        "# Usually, we would utilize something like beam search\n",
        "def greedy_decode(model, src, max_len, start_symbol):\n",
        "  src = src.to(DEVICE)\n",
        "  memory = model.encode(src.view(1,-1), None)\n",
        "  memory = memory.to(DEVICE)\n",
        "  ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "  for i in range(max_len-1):\n",
        "      out = model.decode(ys.view(1,-1), memory, None)\n",
        "      prob = nn.functional.softmax(model.generator(out[:, -1]),dim=1)\n",
        "      _, next_word = torch.max(prob, dim=1)\n",
        "      next_word = next_word.item()\n",
        "\n",
        "      ys = torch.cat([ys,torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "      if next_word == EOS_IDX:\n",
        "          break\n",
        "  return ys\n",
        "\n",
        "# Function for translation\n",
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "  model.eval()\n",
        "  src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
        "  num_tokens = src.shape[0]\n",
        "  tgt_tokens = greedy_decode(model,  src, max_len=num_tokens + 5, start_symbol=SOS_IDX).flatten()\n",
        "  return \" \".join(vocabularies[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<sos>\", \"\").replace(\"<eos>\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "EGcMx_GL5MNl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "( def \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Trying to translate from English to Python\n",
        "print(translate(transformer, \"Def\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
